import google.generativeai as genai
import requests
from bs4 import BeautifulSoup
import numpy as np
import pickle

# ë³¸ì¸ì˜ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”
API_KEY = "AIzaSyA82LrwZs-SBtfl4REcClLGbDv1-Na2iO4"
genai.configure(api_key=API_KEY)

def prepare_and_save_embeddings():
    print("ì„œì¼ëŒ€í•™êµ í™ˆí˜ì´ì§€ ì •ë³´ ìŠ¤í¬ë ˆì´í•‘ ì‹œì‘...")
    urls = {
        "í•™ì‚¬ê³µì§€": "https://www.seoil.ac.kr/seoil/599/subview.do",
        "ê³µì§€ì‚¬í•­": "https://www.seoil.ac.kr/seoil/598/subview.do",
        "í–‰ì‚¬ì•ˆë‚´": "https://www.seoil.ac.kr/seoil/600/subview.do",
        "í™ë³´ì‚¬í•­": "https://www.seoil.ac.kr/seoil/602/subview.do",
        "ì…”í‹€ë²„ìŠ¤": "https://www.seoil.ac.kr/seoil/520/subview.do",
        "ì„œì¼ëŒ€í•™êµ": "https://www.seoil.ac.kr/sites/seoil/index.do",
        "í•™êµì†Œì‹": "https://www.seoil.ac.kr/seoil/616/subview.do",
        "ìŠ¤í„°ë””ê³µê°„": "https://www.seoil.ac.kr/seoil/583/subview.do",
        "PCì´ìš©, VRì‹¤": "https://www.seoil.ac.kr/seoil/584/subview.do",
        "í¸ì˜ì , ì¹´í˜": "https://www.seoil.ac.kr/seoil/585/subview.do",
        "í•™ìƒì‹ë‹¹": "https://www.seoil.ac.kr/seoil/3896/subview.do",
        "íœ´ê²Œê³µê°„": "https://www.seoil.ac.kr/seoil/586/subview.do",
        "í¸ì˜ì‹œì„¤": "https://www.seoil.ac.kr/seoil/587/subview.do",
        "ì²´ìœ¡ì‹œì„¤": "https://www.seoil.ac.kr/seoil/588/subview.do",
        "ëŒ€í•™ìƒí™œë©”ë‰´ì–¼": "https://www.seoil.ac.kr/seoil/3409/subview.do",
        "ì°¾ì•„ì˜¤ì‹œëŠ”ê¸¸": "https://www.seoil.ac.kr/seoil/520/subview.do"


    }
    
    all_chunks = []
    for topic, url in urls.items():
        try:
            response = requests.get(url, timeout=600)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            text = soup.get_text(separator='\n', strip=True)
            for i in range(0, len(text), 500):
                chunk = text[i:i+500]
                all_chunks.append({"topic": topic, "content": chunk})
            print(f"âœ… '{topic}' í˜ì´ì§€ ìŠ¤í¬ë ˆì´í•‘ ì™„ë£Œ")
        except requests.RequestException as e:
            print(f"âŒ '{topic}' í˜ì´ì§€ ìŠ¤í¬ë ˆì´í•‘ ì‹¤íŒ¨: {e}")
            continue

    print("\ní…ìŠ¤íŠ¸ ì¡°ê°ë“¤ì„ ì„ë² ë”©í•˜ëŠ” ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    if not all_chunks:
        print("ìŠ¤í¬ë ˆì´í•‘ëœ ë°ì´í„°ê°€ ì—†ì–´ ì„ë² ë”©ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    contents = [chunk['content'] for chunk in all_chunks]
    embedding_result = genai.embed_content(model="models/embedding-001", content=contents, task_type="RETRIEVAL_DOCUMENT")
    
    vector_store = [{"content": chunk['content'], "embedding": vector} for chunk, vector in zip(all_chunks, embedding_result['embedding'])]
    
    # ì„ë² ë”© ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
    with open("vector_store.pkl", "wb") as f:
        pickle.dump(vector_store, f)
        
    print("\nğŸ‰ ì„ë² ë”© ì™„ë£Œ! 'vector_store.pkl' íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    prepare_and_save_embeddings()