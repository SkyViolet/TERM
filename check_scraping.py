import requests
from bs4 import BeautifulSoup
import pandas as pd

def scrape_and_process_page(topic, url):
    """
    ëª¨ë“  í˜ì´ì§€ì—ì„œ id='_contentBuilder' ì˜ì—­ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” í†µì¼ëœ í•¨ìˆ˜.
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    response = requests.get(url, headers=headers, timeout=30)
    response.raise_for_status()
    soup = BeautifulSoup(response.text, 'html.parser')

    main_content = soup.find(id='_contentBuilder')

    if main_content:
        print(f" INFO: '{topic}' í˜ì´ì§€ì—ì„œ id='_contentBuilder' ë‚´ìš©ì„ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
        return main_content.get_text(separator='\n', strip=True)
    else:
        print(f"  -> WARN: '{topic}' í˜ì´ì§€ì—ì„œ id='_contentBuilder' ì˜ì—­ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.")
        return soup.get_text(separator='\n', strip=True)

# ----------------------------------------------------
# --- í…ŒìŠ¤íŠ¸ ì„¤ì • ---
# ğŸ‘‡ í™•ì¸í•˜ê³  ì‹¶ì€ í˜ì´ì§€ì˜ ì£¼ì œì™€ URLì„ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš” ğŸ‘‡
TOPIC_TO_CHECK = "ì°¾ì•„ì˜¤ì‹œëŠ”ê¸¸"
URL_TO_CHECK = "https://www.seoil.ac.kr/seoil/520/subview.do"
# ----------------------------------------------------

# --- ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„ ---
if __name__ == "__main__":
    print(f"--- '{TOPIC_TO_CHECK}' í˜ì´ì§€ ìŠ¤í¬ë ˆì´í•‘ ê²°ê³¼ í™•ì¸ ì‹œì‘ ---\n")
    try:
        final_text = scrape_and_process_page(TOPIC_TO_CHECK, URL_TO_CHECK)
        
        print("\n--- [AIì—ê²Œ ì „ë‹¬ë  ìµœì¢… í…ìŠ¤íŠ¸] ---\n")
        if final_text and final_text.strip():
            print(final_text)
        else:
            print("!!! í…ìŠ¤íŠ¸ë¥¼ ì „í˜€ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. !!!")
        print("\n--- [í™•ì¸ ì™„ë£Œ] ---")

    except Exception as e:
        print(f"âŒ ìŠ¤í¬ë ˆì´í•‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")